#!/home/drahflow/elymas/elymas/loaded

{ { _ sys .asm .rawAddress txt .produce .u defv }' scope }
<
  /generate deffd
  0 ==m # placeholder, zero value is never read
  { =m [ m .v keys { m .v -01 . } each ] }' "#dom" defmd
  { =m m .v ==v =*f v keys { v -01 . f }' each } "#each" defmd
  { 0 } "#istart" deffd
  { =m m .v keys len eq }' "#iend" defmd
  { 1 add }" "#istep" deffd
  { =m m .v keys * }' "#itrans" defmd
  { =m m .v -01 sys .asm .rawAddress txt .produce .u .?' }' /has defmd
  { =m m .v ==v "#iclone" | * ==n v keys { _ v -01 . -01 n =[] } each n }' /clone defmd
  { < generate ==v "put" =* > }' _ "#iclone" deffd
> -- /objset deffd

{ { 0 } ? * not not } /andif deffd

map ==constants
map ==assertions
objset ==blocks
{ # ==parentBlock
  < map ==f map ==e list ==d map ==v _ ==parent >' _ blocks .put
} /childBlock deffd
< > childBlock _ ==emptyBlock ==currentBlock

< map ==:cache { _ cache .has not { _ _ cache =[] }" rep cache * }' > -- /makeUnique deffd

<
  { sys .linux .gettimeofday -- 1000000 mul add } /t deffd
  < { == }' > ==time =*setTime
  < { == }' > ==count =*setCount
  { ==l 0 l setTime 0 l setCount 
    { =*f { t ==start f t start sub time l . add l setTime count l . 1 add l setCount } }
    quoted not { * } rep
  }
  { time keys { _ dump _ time -01 . txt .produce .u " μs" cat dump count -01 . txt .produce .u " calls" cat dump } each }
> -- /perfstats deffd "τ" defq

<
  { -- } "$$" defq # { ==name _ "$" name cat " " cat -01 cat dump } "$$" deffd

  txt .consume .|hu "%" defq
  { "2120" "-" | |le "021" "-" | |ge |and } /in defq
  { "Unconfigured peek/take/get/set/noErr/snip" die } -000000 =*peek =*take =*get =*set =*noErr =*snip { } =*setupInput
  { | { ==:f /f sys .executeIdentifier _ * -- } * }" "@" deffd
  str .|infix =*:infix

  # parser generator
  { _ sys .typed .type 1 eq { ==str { 1 ==r str { peek eq r and =r take }' each r _ |noErr rep }' } { }" ? * } /lit deffd
  { lit =*p { get , p { --, ,-- }" { ,--- set }" ? * 1 }' } ",?" deffd
  { lit =*p { { get , p }' { --, ,-- }' loop ,--- set 1 }' } ",*" deffd
  { _ ,* ,; } ",+" deffd
  { lit =*q lit =*p { get , p { --, ,-- 1 }" { ,--- set q }" ? * }' } ",|" deffd
  { lit ==q lit =*p { p q { 0 }" ? * }' } ",;" deffd
  { [ [ }" { ] |lit each ] ",;" | fold }" -01 ",[" deffd ",]" deffd
  { defvst }' =*:defp
  {
    ==name "}'" | * { ,[ }' -01 ; { ,] }' ; { * _ name "_make" cat defp * }_ name "_make" cat defp
    "{" | * name "_make" cat "|" | "*" | "}'" | * name defp
  } "}==" defq
  "{" | "(" defq { 1 "}'" | * }' ")" defq

  { lit =*p lit =*q {
    { get , p { ,--- _ set , 0 }" { ,--- _ set , q }" ? * }' { --, ,-- }' loop ,--- set 1
  }' } /upto deffd

  # compare Specification of the Metamath Language
  { { peek take %24 neq }' { }' loop 1 }" ==sequenceEndingInDollar
  { peek take ==c c %09 eq c %0A eq or c %0C eq or c %0D eq or c %20 eq or } ==whitechar
  { peek take ==c c %41 %5A in c %61 %7A in or c %30 %39 in or c %2D eq or c %5F eq or c %2E eq or } ==labelchar
  { peek take ==c c %41 %5A in c %3F eq or } ==compressedchar
  { peek take ==c c %24 neq c %20 gt and c %7F lt and } ==mathchar

  { "$(" sequenceEndingInDollar ")" upto ")" white }==comment
  { whitechar comment ,| include ,| ,+ }==white
  { "$[" white ( |setupInput get ) mathchar ,* (
    get snip "including: " -1101 cat dump parseFile "finished " -01 cat dump *
  ) white "$]" white }==include

  { ( get ) mathchar ,+ ( get snip makeUnique ) white }==mathsymbol
  { ( get ) labelchar ,+ ( get snip makeUnique ) white }==label

  { "$c" white ,[ mathsymbol ( $$c 1 -01 constants =[] ) ,] ,+ "$." white }==cstatement
  { "$v" white ,[ mathsymbol ( $$v 1 -01 currentBlock .v =[] ) ,] ,+ "$." white }==vstatement
  { label "$f" white ( $$f [ ) mathsymbol mathsymbol ( ] -01 currentBlock .f =[] ) "$." white }==fstatement
  { label "$e" white ( $$e [ ) mathsymbol mathsymbol ,* ( ] -01 currentBlock .e =[] ) "$." white }==estatement
  { "$d" white ( [ ) mathsymbol mathsymbol ,+ ( ] currentBlock .d .append1 ) "$." white }==dstatement
  { label "$a" white ( $$a [ ) mathsymbol mathsymbol ,* ( ]
    < "a" ==type currentBlock ==ctx ==thm { "Assumption has no proof" die }" =*proof _ ==name
      { mandatoryHypotheses ==hyps }' { mandatoryDisjunct ==disj }' { allDisjunct ==allDisj }' > -01*02*03*0
    -01 assertions =[] ) "$." white
  }==astatement

  { "?" ( "?" ) white }==questionmark
  { ( [ ) label questionmark ,| ,* ( ] { -- }_ ) }==proof
  { "(" white ( [ ) label ,* ( ] ) ")" white ( [ ) ,[ ( get ) ,[ compressedchar ,] ,+ ( get snip ) white ,] ,* ( ] |cat fold
    < ==data _ ==labels len ==labelCount { _ ==hypotheses len ==hypCount
      [ 0 data { ==c
        [
          { c %41 ge c %54 le and } { 20 mul c %40 sub add _ dump ==n
          [
            { n 1 sub hypCount lt } { n 1 sub hypotheses * }
            { n 1 sub hypCount sub labelCount lt } { n 1 sub hypCount sub labels * } 
            { 1 } { n 1 sub hypCount sub labelCount sub txt .produce .u "@ " -01 cat }
          ] conds
          0 }
          { c %55 ge c %59 le and } { 5 mul c %54 sub add _ dump }
          { c %5A eq } { -- "!" 0 }
          { c %3F eq } { -- "?" 0 }
          { 1 } { "Invalid compressed proof" die }
        ] conds
      } each -- ]
    } > -- ) }==compressedproof
  { label "$p" white ( $$p [ ) mathsymbol mathsymbol ,* ( ] ) "$="
    white compressedproof proof ,| (
    < "p" ==type currentBlock ==ctx -01 ==thm =*proof _ ==name
      { mandatoryHypotheses ==hyps }' { mandatoryDisjunct ==disj }' { allDisjunct ==allDisj }' > -01*02*03*0
    # -101 "simpl31" eq { perfstats "done" die } rep
    # -101 "vtoclga" eq { perfstats "done" die } rep
    # _ "a17d" eq { -101 verifyProof "done" die } rep # TODO: this line is just debugging
    # -100 verifyProof dump
    -01 assertions =[] ) "$." white
  }==pstatement

  { "${" ( currentBlock childBlock =currentBlock ) white statements ( currentBlock .parent =currentBlock ) "$}" white }==block
  { [ estatement pstatement dstatement block vstatement fstatement astatement cstatement white ] ",|" | fold ,* }==statements

  { ":" via
    "" ==s 0 ==i 0 ==slen 0 ==last 0 ==eof
    {
      {
        i slen lt not {
          eof not {
            s 1024 1024 mul :read cat =s
            s len _ =slen
                    txt .produce .u "Just read to: " -01 cat dump }" rep
        }" rep
        i slen lt { i s * }" { 1 neg 1 =eof }" ? *
      }' =peek
      { i 1 add =i }' =take { i }' =get { =i }' =set { i =last }' =noErr { s infix }' =snip
    } _ =setupInput *

    { statements * { i s len neq { ??metamath.trailing-garbage } rep } { ??metamath } ? * }
      { -- < last s str .postfix ==remaining > ??!' } ?!metamath
  }
> -- /parse deffd

{ sys .file _ ":" via -01 :open parse :close } /parseFile deffd

{ ==ctx ==sym 0 ==found { ctx .?'v found not and }' { sym ctx .v ==v v .has found or =found ctx .parent =ctx }' loop found } /isVar deffd
{ ==ctx ==lbl 0 ==found { ctx .?'e found not and }' { lbl ctx .e ==e e .has found or =found ctx .parent =ctx }' loop found } /isEHyp deffd
{ ==ctx ==lbl 0 ==found { ctx .?'f found not and }' { lbl ctx .f ==f f .has found or =found ctx .parent =ctx }' loop found } /isFHyp deffd
{ -01 ==lbl { _ .e lbl -01 .has not }' { .parent }' loop .e lbl -01 * } /getEHyp deffd
{ -01 ==lbl { _ .f lbl -01 .has not }' { .parent }' loop .f lbl -01 * } /getFHyp deffd
{ constants .has }' /isConst deffd

{ _ ==pstm .ctx ==ctx map _ ==vars # will be returned
  { ==sym [
    { sym ctx isVar }' { 1 sym vars =[] }'
    { sym isConst }' { }'
    { 1 }' { "Undeclared symbol: " sym cat die }'
  ] conds } ==collect

  pstm .thm collect each
  ctx { _ .?'e }' { _ .e { collect each }' each .parent }' loop --
} /mandatoryVariables deffd

{ _ ==pstm mandatoryVariables ==vars list _ ==hyps # will be returned
  [ pstm .ctx { _ .?'e }' { _ .parent }' loop -- ] reverse ==ctxs
  ctxs { _ ==ctx .f dom { _ ==k ctx .f * 1 -01 * vars .has { k hyps .append1 }' rep } each } each
  ctxs { .e dom { hyps .append1 }' each }' each
} /mandatoryHypotheses deffd

{ ==pstm list _ ==disj # will be returned
  [ pstm .ctx { _ .?'d }' { _ .parent }' loop -- ] reverse ==ctxs
  ctxs { .d { _ len ==l ==dstm
    0 l range { ==i
      i 1 add l range { ==j
        [ i dstm * j dstm * ] disj .append1
      } each
    } each
  } each }' each
} /allDisjunct deffd

{ _ ==pstm mandatoryVariables ==vars list _ ==disj # will be returned
  # "Vars: " dump
  # vars dom dump
  [ pstm .ctx { _ .?'d }' { _ .parent }' loop -- ] reverse ==ctxs
  ctxs { .d { # _ dump
    ==dstm
    0 dstm len range { _ ==i dstm * vars .has {
      i 1 add dstm len range { _ ==j dstm * vars .has {
        [ i dstm * j dstm * ] disj .append1
      }' rep } each
    }' rep } each
  } each }' each
} /mandatoryDisjunct deffd

{ _ ==pstm _ .hyps ==hyps .disj ==disj
  "Mandatory hyps: " dump
  hyps |dump each
  "Mandatory disjunct: " dump
  disj |dump each
  "^^^^^^^^^^^^^^^^^^^" dump

  hyps pstm .proof
} /computeProof deffd

{ _ ==pstm _ .ctx ==ctx computeProof
    list ==stack # the verification stack
    list ==savedTheorems # Z-saved theorems
  _ dump { ==lbl
    [
      { lbl ctx isEHyp } { lbl ctx getEHyp stack .append1 }
      { lbl ctx isFHyp } { lbl ctx getFHyp stack .append1 }
      { lbl "!" eq } { stack len 1 sub stack * savedTheorems .append1 }
      { lbl len _ { -- 0 lbl * 0 "@" * eq } rep }
        { 2 lbl str .postfix txt .consume .u savedTheorems * stack .append1 }
      { lbl assertions .has } {
        "Applying: " lbl cat dump
        
        lbl assertions * _ ==ass .hyps ==hyps
        map ==substitution

        "Mandatory hypotheses:" dump
        hyps dump
        0 hyps len range
          _ { hyps * dump } each
        _ { _ ==i hyps * _ ==h ass .ctx isFHyp {
            h ass .ctx getFHyp ==mask
            stack len hyps len sub i add stack * ==target
            0 mask * 0 target * neq { mask dump target dump "Constant symbol mismatch" die } rep
            [ 1 target len range { target * } each ] 1 mask * substitution =[]
          } rep } each

          substitution dom { ==k k " => " cat k substitution * { " " -01 cat cat } fold cat dump } each

          { _ ==i hyps * _ ==h ass .ctx isEHyp {
              stack len hyps len sub i add stack * ==target
              [ h ass .ctx getEHyp { # ==sym
                _ ass .ctx isVar { substitution * _ len dearray } rep
              } each ] ==mask
              mask target eq all not { mask dump target dump "Hypthesis does not match stack" die } rep
          } rep } each

        ass .disj { =*d
          "Checking disjunct " 0 d cat " <=> " cat 1 d cat dump
          0 d substitution * { ass .ctx isVar } grep { ==v
            1 d substitution * { ass .ctx isVar } grep { ==w
                v " :=: " w cat cat dump
                v w eq { "Disjunct variable requirement broken" die } rep
                [ pstm .allDisj { =*d 0 d v eq 1 d w eq and 0 d w eq 1 d v eq and or } each ] any not
                  { "Disjunct variable requirement not carried" die } rep
            } each
          } each
        } each

        "All checks ok. Inserting new statement." dump

        hyps len { stack .pop } rep
        [ ass .thm { _ ass .ctx isVar { substitution * _ len dearray } rep } each ] stack .append1
      }
      { 1 } { "Invalid proof step: " lbl cat die }
    ] conds
    
    "Proof stack" dump
    stack { { " " -01 cat cat } fold dump } each
    "^^^^^^^^^^^" dump
  } each

  [
    { stack len 1 neq } { "Stack not empty after proof." dump 0 }
    { 0 stack * pstm .thm eq all not } { "Final stack contents: " dump 0 stack * dump "and theorem: " pstm .thm dump "do not match" dump 0 }
    { 1 } { 1 }
  ] conds
} /verifyProof deffd

{
  sys .|argv len 2 neq { "usage: ./igor input.mm" die } rep
  1 sys .argv * parseFile
} { _ dump _ keys dump .remaining die } ?!metamath

{ =*f 0 ==computed "" ==?result {
  computed not { 1 =computed f =result } rep
  result
} } /memoized deffst

{ ==ctx map _ ==result # returned
  [ ctx { _ .?'e }' { _ .parent }' loop -- ] reverse ==ctxs
  ctxs { _ ==c .f _ =*fs dom { _ fs -01 result =[] } each } each
} /collectFHyps deffst

{ ==ctx map _ ==result # returned
  [ ctx { _ .?'e }' { _ .parent }' loop -- ] reverse ==ctxs
  ctxs { _ ==c .e _ =*es dom { _ es -01 result =[] } each } each
} /collectEHyps deffst

<
  { [ } "[|" deffd { ] |cat fold } "|]" deffd

  emptyBlock ==renderContext
  emptyBlock ==userContext
  emptyBlock ==proofContext

  { ==name
    [
      { name constants .has } {
        [| "\e[37m" name "\e[0m" |]
      }
      { name assertions .has } {
        name assertions * ==a
        [
          { a .type "p" eq } { [| "\e[36m" name "\e[0m" |] }
          { a .type "a" eq } { [| "\e[31m" name "\e[0m" |] }
          { 1 } { name }
        ] conds
      }
      { name renderContext isVar } { [| "\e[32m" name "\e[0m" |] }
      { name "^\\$" regex } { [| "\e[33m" name "\e[0m" |] }
      { 1 } { name }
    ] conds
  } /renderName deffd

  "" ==inputBuffer
  {
    0 ==eof
    { eof not { inputBuffer "^([^\n]*\n)(.*)" regex not } andif } {
      65536 sys .in .read _ ==input "" eq =eof
      inputBuffer input cat =inputBuffer
    } loop eof { "" } { -01 =inputBuffer } ? *
  } /inputLine deffd

  sys .out .|writeall /out deffd

  { -- } /showBlock deffd

  { ==a
    a .ctx _ =renderContext _ =userContext showBlock
    [| "assuming:\n" |] out
    a .hyps { ==hyp
      [
        { hyp userContext isEHyp } {
          [| "$e " hyp renderName "\n" |] out
          [| hyp userContext getEHyp { renderName " " } each "\n" |] out
        }
        { hyp userContext isFHyp } {
          [| "$f " hyp renderName "\n" |] out
          [| hyp userContext getFHyp { renderName " " } each "\n" |] out
        }
        { 1 } {
          [| "\e[31mcould not resolve hypothesis:\e[0m " hyp "\n" |] out
        }
      ] conds
    } each
    [| "gives:\n" |] out
    [| a .thm { renderName " " } each "\n" |] out
    " " ==sep
    [| "mandatory disjunct:" a .disj { =*d sep ", " =sep 0 d renderName " <!> " 1 d renderName } each "\n" |] out
    " " =sep
    [| "all disjunct:" a .allDisj { =*d sep ", " =sep 0 d renderName " <!> " 1 d renderName } each "\n" |] out
  } /showAssertion deffd

  { ==p
    p showAssertion
  } /showProposition deffd

  { ==name
    [
      { name constants .has } {
        [| "$c " name renderName "\n" |] out
      }
      { name assertions .has } {
        name assertions * ==a
        [
          { a .type "p" eq } { [| "$p " name renderName "\n" |] out a showProposition }
          { a .type "a" eq } { [| "$a " name renderName "\n" |] out a showAssertion }
          { 1 } { [| name " is an assertion of unknown type (probably a bug)\n" |] out }
        ] conds
      }
      { name userContext isEHyp } {
        [| "$e " name renderName "\n" |] out
        [| name userContext getEHyp { renderName " " } each "\n" |] out
      }
      { name userContext isFHyp } {
        [| "$f " name renderName "\n" |] out
        [| name userContext getFHyp { renderName " " } each "\n" |] out
      }
      { name userContext isVar } {
        [| "$v " name renderName "\n" |] out
      }
      { 1 } {
        [| name " is not known" "\n" |] out
      }
    ] conds
  } /show deffd

  { ==prompt
    0 ==numberRead
    { numberRead not } {
      prompt "> " cat sys .out .writeall
      inputLine ==input
      input "^ *(\\d+)\n" regex { 1 =numberRead txt .consume .u } rep
    } loop
  } /readNumber deffd

  { ==assertionTokens ==tokens map ==substitution
    1 ==valid
    0 ==i
    assertionTokens { ==tok
      [
        { tok constants .has
          { i tokens len lt } andif
          { i tokens * tok eq } andif
        } { i 1 add =i }

        { tok constants .has not
          { i tokens len lt } andif
          { i tokens tok variables * logicParsers * * } andif
        } { ==end ==parse
          parse logicRange tokens * ==new
          tok substitution .has {
            tok substitution * ==old
            old new len eq { old new eq all } andif valid and =valid
          } {
            new tok substitution =[]
          } ? *
          end =i
        }

        { 1 } { 0 =valid }
      ] conds
    } each

    i tokens len eq valid and =valid

    list _ ==result # returned
    valid { substitution result .append1 } rep
  } /possibleSubstitutionsForToks deffd

  { .thm possibleSubstitutionsForToks } /possibleSubstitutions deffd

  { ==substitution ==tokens
    [ tokens { _ substitution .has { substitution * _ len dearray } rep } each ]
  } /applySubstitution deffst

  { <
    ==thm < > ==resolution 1 ==isopen

    { < > =resolution 1 =isopen } =*open
    { =resolution 0 =isopen } =*close
  > } /goal deffst

  { < ==theorem ==substitution ==hypotheses > } /step deffst

  { # ==goal
    objset ==goals
    {
      _ .isopen { goals .put } { .resolution .hypotheses |collect each } ? *
    } /collect deffst
    collect goals dom
  } /openGoals deffst

  { ==proposition

    map ==disj map ==nonDisj
    { ==x ==y
      x y gt { x y =x =y } rep
      x disj .has not { map x disj =[] } rep
      1 y x disj * =[]
    } /markDisj deffst

    { ==x ==y
      x y gt { x y =x =y } rep
      x nonDisj .has not { map x nonDisj =[] } rep
      1 y x nonDisj * =[]
    } /markNonDisj deffst

    { ==x ==y
      x y gt { x y =x =y } rep
      x nonDisj .has {
        y x nonDisj * .has
      } { 0 } ? *
    } /mustNotDisj deffst


    proposition .ctx _ =proofContext
    proposition .thm goal ==mainGoal
    proposition .allDisj { 2 dearray markDisj } each
    0 ==selectedGoal
    0 ==nextMetaVariable
    map ==lastMetaVariables
    map ==metaSubstitution
    1 ==redisplay
    [ ] ==lastSearch

    { _ ==old ==toks
      {
        toks metaSubstitution applySubstitution =toks
        old toks len eq { old toks eq all } andif not
      } { toks =old } loop
      toks
    } /expandMeta deffst

    { ==theorem ==substitution
      theorem mandatoryVariables dom { ==var
        var constants .has not {
          var substitution .has not {
            [| "$" var "." nextMetaVariable _ 1 add =nextMetaVariable txt .produce .u |] ==newVar
            newVar var lastMetaVariables =[]
            [ newVar ] var substitution =[]
          } rep
        } rep
      } each
    } /introduceMetaVars deffst

    { ==closedGoal ==substitution ==theorem
      [| "applying with:\n" |] out
      substitution dom { ==name
        [| name " = " name substitution * { renderName " " } each "\n" |] out
      } each

      substitution theorem introduceMetaVars

      0 ==disjunctionsViolated
      theorem .disj { 2 dearray ==x ==y
        x substitution * { ==xTok
          xTok constants .has not {
            y substitution * { ==yTok
              yTok constants .has not {
                xTok yTok eq {
                  1 =disjunctionsViolated
                  [| "\e[31mproposed application would violate\e[0m " x renderName " <!> " y renderName "\n" |] out
                  0 =redisplay
                } rep
                xTok yTok mustNotDisj {
                  1 =disjunctionsViolated
                  [| "\e[31mproposed application would violate\e[0m " x renderName " <=> " y renderName "\n" |] out
                  0 =redisplay
                } rep
              } rep
            } each
          } rep
        } each
      } each

      disjunctionsViolated not {
        theorem .disj { 2 dearray ==x ==y
          x substitution * { ==xTok
            xTok constants .has not {
              y substitution * { ==yTok
                yTok constants .has not { xTok yTok markDisj } rep
              } each
            } rep
          } each
        } each

        list ==hypotheses
        theorem .hyps { ==name
          [
            { name theorem .ctx isEHyp } {
              name theorem .ctx getEHyp substitution applySubstitution goal hypotheses .append1
            }
            { name theorem .ctx isFHyp } {
              name theorem .ctx getFHyp substitution applySubstitution goal hypotheses .append1
            }
            { 1 } {
              [| "hypothesis " name " cannot be resolved" "\n" |] out
            }
          ] conds
        } each

        hypotheses len not {
          rebuildClosedGoalIndex
        } rep

        hypotheses substitution theorem step closedGoal .close
      } rep
    } /applyTheorem deffst

    { ==assertion ==substitution
      assertion .name dump
      substitution dom { ==v
        [| v " = " v substitution * { renderName " " } each "\n" |] out
      } each
      assertion .hyps { assertion .ctx isEHyp } grep { ==name
        name assertion .ctx getEHyp ==toks
        0 toks * "|-" eq { 1 toks /wff logicParsers * * } andif toks fullyParsed { ==parse
          parse logicNonTerminal /wi eq
              { 0 parse * logicNonTerminal /wceq eq } andif
              { 1 parse * logicNonTerminal /wb eq } andif {
            0 0 parse * * logicRange toks * ==leftVar
            1 0 parse * * logicRange toks * ==rightVar
            0 1 parse * * logicRange toks * ==leftTerm
            1 1 parse * * logicRange toks * ==rightTerm
            leftVar len 1 eq { rightVar len 1 eq } andif {
              leftTerm len 1 eq
                  { 0 leftTerm * substitution .has } andif
                  { 0 rightTerm * substitution .has not } andif {
                0 leftTerm * substitution * leftVar rightVar rewriteTokens
                  0 rightTerm * substitution =[]
              } rep
              rightTerm len 1 eq
                  { 0 rightTerm * substitution .has } andif
                  { 0 leftTerm * substitution .has not } andif {
                0 rightTerm * substitution * rightVar leftVar rewriteTokens
                  0 leftTerm * substitution =[]
              } rep
            } rep
          } rep
        } rep
      } each
    } /resolveEhypSubstitutions deffst

    { ==allowIndirectUsage ==goal ==name
      [| "using: " name "\n" |] out
      [
        { name assertions .has } {
          name assertions * ==a
          [
            { a .type "p" eq a .type "a" eq or } {
              goal .thm expandMeta _ ==goalToks
              goalToks a possibleSubstitutions ==choices

              0 ==indirectUsage
              allowIndirectUsage
              { choices len 0 eq } andif
              { 0 goalToks * "|-" eq } andif
              { 1 goalToks /wff logicParsers * * } andif goalToks fullyParsed { ==goalParse
                0 a .thm * "|-" eq
                { 1 a .thm /wff logicParsers * * } andif a .thm fullyParsed { ==assertionParse
                  goalParse logicNonTerminal /wi eq {
                    [ "|-" ] 1 goalParse * logicRange goalToks * cat a possibleSubstitutions ==implChoices
                    implChoices len 1 eq {
                      /a1i goal use
                      goal .isopen not {
                        name 2 goal .resolution .hypotheses * use
                        1 =indirectUsage
                      } rep
                    } rep
                  } rep

                  indirectUsage not {
                    0 ==hasAntes
                    goalParse logicNonTerminal /wi eq {
                      1 goalParse * 1 =hasAntes
                    } {
                      goalParse
                    } ? * logicRange goalToks * ==relevantGoalToks
                    assertionParse ==i [ ] ==path
                    {
                      [
                        { i logicNonTerminal /wb eq } {
                          relevantGoalToks 1 i * logicRange a .thm * possibleSubstitutionsForToks ==rightChoices
                          relevantGoalToks 0 i * logicRange a .thm * possibleSubstitutionsForToks ==leftChoices

                          # prefer substitutions with more variables known (i.e. better match)
                          rightChoices len 1 eq { leftChoices len 1 eq { 0 leftChoices * dom len 0 rightChoices * dom len gt } andif not } andif {
                            0 rightChoices * ==substitution
                            substitution a resolveEhypSubstitutions
                            substitution a introduceMetaVars
                            path dump # TODO: this is presumably important
                            1 =indirectUsage
                            hasAntes {
                              /sylib goal use
                              goal .isopen not {
                                0 i * logicRange a .thm * substitution applySubstitution /ps lastMetaVariables * let
                                name 4 goal .resolution .hypotheses * .thm expandMeta canUse {
                                  name 4 goal .resolution .hypotheses * use
                                } rep
                              } rep
                            } {
                              /mpbi goal use
                              goal .isopen not {
                                0 i * logicRange a .thm * substitution applySubstitution /ph lastMetaVariables * let
                                name 3 goal .resolution .hypotheses * .thm expandMeta canUse {
                                  name 3 goal .resolution .hypotheses * use
                                } rep
                              } rep
                            } ? *
                          } {
                            leftChoices len 1 eq {
                              0 leftChoices * ==substitution
                              substitution a resolveEhypSubstitutions
                              substitution a introduceMetaVars
                              path dump # TODO: this is presumably important
                              1 =indirectUsage
                              hasAntes {
                                /sylibr goal use
                                goal .isopen not {
                                  1 i * logicRange a .thm * substitution applySubstitution /ps lastMetaVariables * let
                                  name 4 goal .resolution .hypotheses * .thm expandMeta canUse {
                                    name 4 goal .resolution .hypotheses * use
                                  } rep
                                } rep
                              } {
                                /mpbir goal use
                                goal .isopen not {
                                  1 i * logicRange a .thm * substitution applySubstitution /ps lastMetaVariables * let
                                  name 3 goal .resolution .hypotheses * .thm expandMeta canUse {
                                    name 3 goal .resolution .hypotheses * use
                                  } rep
                                } rep
                              } ? *
                            } rep
                          } ? *
                          0
                        }
                        { i logicNonTerminal /wi eq } {
                          relevantGoalToks 1 i * logicRange a .thm * possibleSubstitutionsForToks ==rightChoices
                          rightChoices len 1 eq {
                            0 rightChoices * ==substitution
                            substitution a resolveEhypSubstitutions
                            substitution a introduceMetaVars
                            path dump # TODO: this is presumably important
                            1 =indirectUsage
                            hasAntes {
                              /syl goal use
                              goal .isopen not {
                                0 i * logicRange a .thm * substitution applySubstitution /ps lastMetaVariables * let
                              } rep
                            } {
                              /ax-mp goal use
                              goal .isopen not {
                                0 i * logicRange a .thm * substitution applySubstitution /ph lastMetaVariables * let
                              } rep
                            } ? *
                            goal .isopen not {
                              name 3 goal .resolution .hypotheses * .thm expandMeta canUse {
                                name 3 goal .resolution .hypotheses * use
                              } rep
                            } rep
                          } {
                            # TODO: push to path and hope for the best
                          } ? *
                          0
                        }
                        { 1 } { 0 }
                      ] conds
                    } { } loop
                  } rep
                } rep
              } rep

              indirectUsage not {
                [
                  { choices len 0 eq } {
                    [| "\e[31mno possible substitutions\e[0m\n" |] out
                    0 =redisplay
                    name show
                  }
                  { choices len 1 eq } {
                    a 0 choices * goal applyTheorem
                  }
                  { choices len 1 ge } {
                    [| "\e[31mmultiple substitutions possible\e[0m\n" |] out
                    0 =redisplay
                    name show
                    0 choices len range { ==i
                      [| i txt .produce .u ") " a .thm i choices * applySubstitution { renderName " " } each "\n" |] out
                      [| "(with " i choices * dom { ==v v "=" v i choices * * { " " } each " " } each ")\n" |] out
                    } each

                    a "choice" readNumber choices * goal applyTheorem
                  }
                ] conds
              } rep
            }
            { 1 } { [| name " is an assertion of unknown type (probably a bug)\n" |] out }
          ] conds
        }
        { name userContext isEHyp } {
          goal .thm expandMeta name userContext getEHyp eq all {
            list map < "f" ==type userContext ==ctx name userContext getEHyp ==thm { "no proof" die } =*proof name ==name >
              step goal .close
          } {
            [| "\e[31mnot applicable:\e[0m $f " name renderName "\n" |] out
            0 =redisplay
          } ? *
        }
        { name userContext isFHyp } {
          goal .thm expandMeta name userContext getFHyp eq all {
            list map < "f" ==type userContext ==ctx name userContext getFHyp ==thm { "no proof" die } =*proof name ==name >
              step goal .close
          } {
            [| "\e[31mnot applicable:\e[0m $f " name renderName "\n" |] out
            0 =redisplay
          } ? *
        }
        { 1 } {
          [| name " is not usable" "\n" |] out
          name show
        }
      ] conds
    } /useGeneric deffst

    { 0 useGeneric } /use deffst
    { 1 useGeneric } /tacUse deffst

    { ==tokens ==name
      0 ==usable
      [
        { name assertions .has } {
          name assertions * ==a
          a .type "p" eq a .type "a" eq or {
            tokens a possibleSubstitutions ==choices
            choices len 1 ge =usable
          } rep
        }
        { name userContext isEHyp } {
          tokens name userContext getEHyp eq all =usable
        }
        { name userContext isFHyp } {
          tokens name userContext getFHyp eq all =usable
        }
      ] conds
      usable
    } /canUse deffst

    { ==metaVar ==tokens
      0 ==disjunctionsViolated
      metaVar dump
      metaVar "^\\$([^.]+)$" regex { ==stem
        stem lastMetaVariables .has { stem lastMetaVariables * =metaVar } rep
      } rep

      tokens { ==x metaVar ==y
        x y gt { x y =x =y } rep
        x disj .has {
          y x disj * .has {
            1 =disjunctionsViolated
            [| "\e[31mproposed let would violate\e[0m " x renderName " <!> " y renderName "\n" |] out
            0 =redisplay
          } rep
        } rep
        x nonDisj .has {
          y x nonDisj * .has {
            1 =disjunctionsViolated
            [| "\e[31mproposed let would violate\e[0m " x renderName " <=> " y renderName "\n" |] out
            0 =redisplay
          } rep
        } rep
      } each
      disjunctionsViolated not {
        tokens metaVar metaSubstitution =[]

        disj dom { ==x
          x disj * dom { ==y
            x metaVar eq { tokens { ==t t constants .has not { t y markDisj } rep } each } rep
            y metaVar eq { tokens { ==t t constants .has not { t x markDisj } rep } each } rep
          } each
        } each
      } rep
    } /let deffst

    { map _ ==directTheoremIndex # returned
      [| "Indexing theorems by text...\n" |] out

      assertions dom { ==name
        name assertions * .ctx collectEHyps dom len not { name proposition .name neq } andif {
          name [| name assertions * .thm { " " } each |] directTheoremIndex =[]
        } rep
      } each
      [ |collectEHyps |collectFHyps ] { =*collect
        proofContext collect ==hyps hyps dom { ==name
          name [| name hyps * { " " } each |] directTheoremIndex =[]
        } each
      } each
    } memoized /directTheoremIndex deffst

    map ==closedGoalIndex
    { map =closedGoalIndex
      { ==goal
        goal .isopen { 1 } {
          [ goal .resolution .hypotheses |recurse each ] any { 1 } {
            [| goal .thm expandMeta { " " } each |] ==txt
            goal txt closedGoalIndex =[]
            0
          } ? *
        } ? *
      } /recurse deffst
      mainGoal recurse --
    } /rebuildClosedGoalIndex deffst

    { ==toTry ==goal
      goal .isopen not {
        toTry { =*f
          goal .resolution .hypotheses { ==g g .isopen { g f } rep } each
        } each
      } rep
    } /tacAttemptNext deffst

    { ==goal
      goal .thm expandMeta ==tokens
      [| tokens { " " } each |] ==txt
      [
        { txt directTheoremIndex .has } {
          txt directTheoremIndex * goal use
          goal [ |auto ] tacAttemptNext
        }
        { txt closedGoalIndex .has } {
          [| "re-using earlier proof\n" |] out
          txt closedGoalIndex * .resolution goal .close
        }
        { 0 tokens * logicParsers .has } {
          { [| "\e[31mautomatic parser available, but did not parse. probably not satisfiable\e[0m\n" |] out } =*failed
          1 tokens 0 tokens * logicParsers * * { tokens len eq { ==parse
            # parse tree order is by token sequence, but hypothesis order is by set.mm
            # only apply topmost parse rule and handle rest via big recursion
            parse logicNonTerminal goal use
            goal [ |auto ] tacAttemptNext
          } |failed ? * } |failed ? *
        }
        { 0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed } { ==parse
          [
            { parse logicNonTerminal /wi eq { 0 parse * logicRange tokens * 1 parse * logicRange tokens * eq all } andif } {
              /id goal use
              goal [ |auto ] tacAttemptNext
            }
            { parse logicNonTerminal /wb eq { 0 parse * logicRange tokens * 1 parse * logicRange tokens * eq all } andif } {
              /biid goal use
              goal [ |auto ] tacAttemptNext
            }
            { parse logicNonTerminal /wi eq { 1 parse * logicNonTerminal /wceq eq } andif
              { 0 1 parse * * logicRange tokens * 1 1 parse * * logicRange tokens * eq all } andif } {
              /a1i goal use
              goal [ |auto ] tacAttemptNext
            }
            { parse logicNonTerminal /wi eq { 1 parse * logicNonTerminal /wal eq } andif
              { 0 parse * logicRange tokens * 1 1 parse * * logicRange tokens * eq all } andif } {
              /ax-17 goal use
              goal [ |auto ] tacAttemptNext
            }
            { parse logicNonTerminal /wceq eq { 0 parse * logicRange tokens * 1 parse * logicRange tokens * eq all } andif } {
              /eqid goal use
              goal [ |auto ] tacAttemptNext
            }
          ] conds

          goal .isopen { parse logicNonTerminal /wi eq } andif {
            1 parse * logicRange tokens * ==target

            goal antecedents { ==ante
              ante len target len eq { ante target eq all } andif {
                goal tacSelect
              } rep
            } each

            proofContext collectEHyps _ ==hyps dom { ==name
              name hyps * len 1 sub target len eq { 1 name hyps * len range name hyps * * target eq all } andif {
                /a1i goal use
                goal .isopen not {
                  name 2 goal .resolution .hypotheses * use
                } rep
              } rep
            } each
          } rep
        }
      ] conds
    } /auto deffst

    { ==tokens
      tokens len 1 eq { 0 0 tokens * * 0 "$" * eq } andif
    } /tokensAreMetaVar deffst

    { ==goal
      { "\e[31mdistr:ante not applicable, expected |- ( ... -> ( ... { <-> , = } ... ) )\e[0m\n" out } =*notApplicable
      goal .thm expandMeta ==tokens
      0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
        parse logicNonTerminal /wi eq {

          < > ==thms "" ==leftNt "" ==rightNt
          [
            { 1 parse * logicNonTerminal /wb eq } {
              0 1 parse * * logicNonTerminal =leftNt
              1 1 parse * * logicNonTerminal =rightNt
              leftNt rightNt eq {
                <
                  [ /imbi1d /imbi2d /imbi12d ] ==wi
                  [ /bibi1d /bibi2d /bibi12d ] ==wb
                  [ /eleq1d /eleq2d /eleq12d ] ==wcel
                  [ /orbi1d /orbi2d /orbi12d ] ==wo
                  [ /anbi1d /anbi2d /anbi12d ] ==wa
                  [ /3anbi1d /3anbi2d /3anbi3d /3anbi12d /3anbi13d /3anbi23d /3anbi123d ] ==w3a
                  [ /3orbi1d /3orbi2d /3orbi3d /3orbi123d ] ==w3o
                  [ /notbid ] ==wn
                  [ /eqeq1d /eqeq2d /eqeq12d ] ==wceq
                  [ /sseq1d /sseq2d /sseq12d ] ==wss
                  [ /albid ] ==wal
                  [ /exbid ] ==wex
                  [ /ralbid /ralbidv2 ] ==wral
                  [ /rexbid /rexbidv2 ] ==wrex
                  [ /breq1d /breq2d /breqd /breq12d /breq123d ] ==wbr
                  [ /releqd ] ==wrel
                > =thms
              } |notApplicable ? *
            }
            { 0 parse * logicNonTerminal /wceq eq { 1 parse * logicNonTerminal /wceq eq } andif } {
              0 1 parse * * logicNonTerminal =leftNt
              1 1 parse * * logicNonTerminal =rightNt
              leftNt rightNt eq {
                <
                  [ /fveq1d /fveq2d /fveq12d ] ==cfv
                  [ /oveq /oveq1d /oveq2d /oveq12d /oveq123d ] ==co
                  [ /opeq1d /opeq2d /opeq12d ] ==cop
                  [ /xpeq1d /xpeq2d /xpeq12d ] ==cxp
                  [ /inteqd ] ==cint
                  [ /abbidv /abbid ] ==cab
                  [ /uneq1d /uneq2d /uneq12d ] ==cun
                  [ /iuneq1d /iuneq2d /iuneq12d ] ==ciun
                  [ /seqeq1d /seqeq2d /seqeq3d /seqeq123d ] ==cseq
                  [ /mpteq12dv ] ==cmpt
                  [ /mpt2eq123dv ] ==cmpt2
                  [ /coeq1d /coeq2d /coeq12d ] ==ccom
                  [ /reseq1d /reseq2d /reseq12d ] ==cres
                  [ /dmeqd ] ==cdm
                  [ /rneqd ] ==crn
                  [ /cnveqd ] ==ccnv
                  [ /unieqd ] ==cuni
                  [ /relexpeq12d ] ==crelexp
                > =thms
              } |notApplicable ? *
            }
          ] conds

          thms leftNt .?' {
            thms leftNt . { ==thm
              goal .isopen { thm goal .thm expandMeta canUse } andif {
                thm goal use
                goal [ |auto |tacDistrAntecedent ] tacAttemptNext
              } rep
            } each

            goal .isopen { [| "\e[31mno theorem succeeded in closing goal, tried: " thms leftNt . { " " } each "\e[0m\n" |] out } rep
          } { [| "\e[31mno theorem known to process rewrite step, of type " leftNt "\e[0m\n" |] out } ? *
        } |notApplicable ? *
      } |notApplicable ? *
    } /tacDistrAntecedent deffst

    { ==goal
      { "\e[31mdistr:ante (meta-version) not applicable, expected |- ( ... -> ( ... { <-> , = } ... ) )\e[0m\n" out } =*notApplicable
      goal .thm expandMeta ==tokens
      0 tokens * "|-" eq { 1 tokens /wff metaLogicParsers * * } andif tokens fullyParsed { ==parse
        parse logicNonTerminal /wi eq {
          [ ] ==leftMeta [ ] ==rightMeta
          [
            { 1 parse * logicNonTerminal [ /wb /wceq ] eq any
              { 0 1 parse * * logicRange tokens * _ =leftMeta tokensAreMetaVar } andif } {
              1 0 parse * * logicRange tokens * ==from
              0 0 parse * * logicRange tokens * ==to
              1 1 parse * * logicRange tokens * from to rewriteTokens 0 leftMeta * let
            }

            { 1 parse * logicNonTerminal [ /wb /wceq ] eq any
              { 1 1 parse * * logicRange tokens * _ =rightMeta tokensAreMetaVar } andif } {
              0 0 parse * * logicRange tokens * ==from
              1 0 parse * * logicRange tokens * ==to
              0 1 parse * * logicRange tokens * from to rewriteTokens 0 rightMeta * let
            }
          ] conds

          goal tacDistrAntecedent
        } |notApplicable ? *
      } |notApplicable ? *
    } /tacDistrAntecedentMeta deffst

    { ==to ==from ==tokens
      [
        0 ==i { i tokens len lt } {
          i from len add tokens len le { i _ from len add range tokens * from eq all } andif {
            to _ len dearray i from len add =i
          } {
            i tokens * i 1 add =i
          } ? *
        } loop
      ]
    } /rewriteTokens deffst

    { ==goal
      { "\e[31mrewrite:ante not applicable, expected |- ( ( ... { = , <-> } ... ) -> ... )\e[0m\n" out } =*notApplicable
      goal .thm expandMeta ==tokens
      0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
        parse logicNonTerminal /wi eq { 0 parse * logicNonTerminal [ /wceq /wb ] eq any } andif {
          0 0 parse * * logicRange tokens * ==from
          1 0 parse * * logicRange tokens * ==to

          /mpbird goal use
          goal .isopen not {
            1 parse * logicRange tokens * from to rewriteTokens /ch lastMetaVariables * let
            goal [ |auto ] tacAttemptNext
            4 goal .resolution .hypotheses * ==g g .isopen { g tacDistrAntecedent } rep
          } rep
        } |notApplicable ? *
      } |notApplicable ? *
    } /tacRewriteAntecedent deffst

    { ==goal ==antecedent
      { "\e[31mrewrite:full not applicable, expected |- ... as goal and ... { = , <-> } ... as argument\e[0m\n" out } =*notApplicable
      goal .thm expandMeta ==tokens
      0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
        0 antecedent /wff logicParsers * * antecedent fullyParsed { ==antecedentParse
          antecedentParse logicNonTerminal [ /wceq /wb ] eq any {
            0 antecedentParse * logicRange antecedent * ==from
            1 antecedentParse * logicRange antecedent * ==to

            /mpbir goal use
            goal .isopen not {
              1 tokens len range tokens * from to rewriteTokens /ps lastMetaVariables * let
              goal [ |auto ] tacAttemptNext
              3 goal .resolution .hypotheses * ==mpbirMaj

              mpbirMaj .isopen {
                /ax-mp mpbirMaj use
                mpbirMaj .isopen not {
                  antecedent /ph lastMetaVariables * let
                  mpbirMaj [ |auto ] tacAttemptNext

                  3 mpbirMaj .resolution .hypotheses * ==g g .isopen { g tacDistrAntecedent } rep
                } rep
              } rep
            } rep
          } |notApplicable ? *
        } |notApplicable ? *
      } |notApplicable ? *
    } /tacRewriteFull deffst

    { ==goal ==name
      name assertions .has {
        name assertions * ==a
        1 a .thm len range a .thm * goal tacRewriteFull
        goal .isopen not {
          3 goal .resolution .hypotheses * ==mpbirMaj
          mpbirMaj .isopen not {
            name 2 mpbirMaj .resolution .hypotheses * use
          } rep
        } rep
      } {
        [| "\e[31m" name " is not an assertion" "\e[0m\n" |] out
      } ? *
    } /tacExpand deffst

    { ==goal
      goal .thm expandMeta ==tokens
      list _ ==antecedents # returned
      0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
        parse logicNonTerminal /wi eq {
          0 parse * ==anteConjuct
          { anteConjuct logicNonTerminal /wa eq } {
            0 anteConjuct * logicRange tokens * antecedents .append1
            1 anteConjuct * =anteConjuct
          } loop
          anteConjuct logicRange tokens * antecedents .append1
        } rep
      } rep
    } /antecedents deffst

    { ==goal
      { "\e[31mtacSelect not applicable, expected |- ( ... /\\ ... ) -> ... \e[0m\n" out } =*notApplicable
      goal .thm expandMeta ==tokens

      0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
        goal antecedents ==antes
        antes len {
          1 parse * logicRange tokens * ==target
          0 ==i 1 neg ==success
          { i antes len lt } {
            i antes * ==ante
            ante len target len eq { ante target eq all } andif {
              i =success antes len =i
            } rep
            i 1 add =i
          } loop
          
          success antes len 1 sub eq ==lastTerm
          
          success 0 ge {
            { success 1 ge } {
              /adantl goal use
              goal [ |auto ] tacAttemptNext
              goal .isopen {
                1 neg =success
              } {
                3 goal .resolution .hypotheses * =goal
                success 1 sub =success
              } ? *
            } loop
            lastTerm /id /simpl ? goal use
            goal [ |auto ] tacAttemptNext
          } { "\e[31mtacSelect not applicable, consequent not found in antecedents\e[0m\n" out } ? *
        } |notApplicable ? *
      } |notApplicable ? *
    } /tacSelect deffst

    { ==goal
      { "\e[31mtacAndSelect not applicable, expected |- ( ... /\\ ... ) -> ( ... /\\ ... )\e[0m\n" out } =*notApplicable
      goal .thm expandMeta ==tokens
      0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
        parse logicNonTerminal /wi eq {
          1 parse * logicNonTerminal /wa eq {
            /jca goal use
            goal [ |auto |tacAndSelect ] tacAttemptNext
          } {
            goal tacSelect
          } ? *
        } |notApplicable ? *
      } |notApplicable ? *
    } /tacAndSelect deffst

    { ==goal ==tokens
      0 tokens /wff logicParsers * * tokens fullyParsed { --
        /mpcom goal use
        goal .isopen not {
          tokens /ph lastMetaVariables * let
          goal [ |auto ] tacAttemptNext
          3 goal .resolution .hypotheses * tacAndSelect
        } rep
      } { "\e[31mdesired antecedent did not parse as valid wff, would never be satisfiable\e[0m\n" out } ? *
    } /tacUnder deffst

    { ==goal ==tokens
      0 tokens /wff logicParsers * * tokens fullyParsed { --
        /mpd goal use
        goal .isopen not {
          tokens /ps lastMetaVariables * let
          goal [ |auto ] tacAttemptNext
          3 goal .resolution .hypotheses * tacAndSelect
        } rep
      } { "\e[31mdesired antecedent did not parse as valid wff, would never be satisfiable\e[0m\n" out } ? *
    } /tacWith deffst

    { ==goal ==tokens
      0 tokens /wff logicParsers * * tokens fullyParsed { --
        /syl goal use
        goal .isopen not {
          tokens /ps lastMetaVariables * let
          goal [ |auto ] tacAttemptNext
          3 goal .resolution .hypotheses * tacAndSelect
        } rep
      } { "\e[31mdesired antecedent did not parse as valid wff, would never be satisfiable\e[0m\n" out } ? *
    } /tacWithOnly deffst

    { ==goal ==tokens
      0 tokens /wff logicParsers * * tokens fullyParsed { ==parse
        goal .thm expandMeta ==goalToks
        0 goalToks * "|-" eq { 1 goalToks /wff logicParsers * * } andif goalToks fullyParsed { ==goalParse
          goalParse logicNonTerminal /wi eq
            /mpancom /ax-mp ? goal use
          goal .isopen not {
            tokens /ph lastMetaVariables * let
            goal [ |auto ] tacAttemptNext
          } rep
        } { "\e[31mcurrent goal is not |- ...\e[0m\n" out } ? *
      } { "\e[31mdesired conclusion did not parse as valid wff, would never be satisfiable\e[0m\n" out } ? *
    } /tacConclude deffst

    { ==goal ==tokens
      0 tokens /wff logicParsers * * tokens fullyParsed { ==parse
        goal .thm expandMeta ==goalToks
        0 goalToks * "|-" eq { 1 goalToks /wff logicParsers * * } andif goalToks fullyParsed { ==goalParse
          goalParse logicNonTerminal /wi eq {
            0 goalParse * logicNonTerminal /wa eq {
              /sylancom goal use
              goal .isopen not {
                tokens /ch lastMetaVariables * let
              } rep
            } {
              /syl goal use
              goal .isopen not {
                tokens /ps lastMetaVariables * let
              } rep
            } ? *
            goal [ |auto ] tacAttemptNext
          } { "\e[31current goal is not |- ( ... -> ... )\e[0m\n" out } ? *
        } { "\e[31mcurrent goal is not |- ...\e[0m\n" out } ? *
      } { "\e[31mdesired conclusion did not parse as valid wff, would never be satisfiable\e[0m\n" out } ? *
    } /tacAndConclude deffst

    { ==goal
      goal .thm expandMeta ==tokens
      0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
        parse logicNonTerminal /wi eq {
          goal ==toRewrite
          0 parse * logicNonTerminal /wa eq {
            /imp goal use
            goal .isopen not {
              3 goal .resolution .hypotheses * =toRewrite
            } rep
          } rep
          toRewrite tacRewriteAntecedent
          toRewrite .isopen not {
            3 toRewrite .resolution .hypotheses * ==continuation
            /a1i continuation use
            continuation [ |auto ] tacAttemptNext
          } rep
          goal [ |auto ] tacAttemptNext
        } { "\e[31mcurrent goal is not |- ( ... -> ... )\e[0m\n" out } ? *
      } { "\e[31mcurrent goal is not |- ...\e[0m\n" out } ? *
    } /tacContinueWithRewrite deffst

    { ==goal
      goal antecedents ==antes
      0 ==doRewrite
      antes { ==ante
        0 ante /wff logicParsers * * ante fullyParsed { ==parse
          parse logicNonTerminal [ /wa /w3a ] eq any { 1 =doRewrite } rep
        } rep
      } each

      doRewrite {
        {
          goal .thm expandMeta ==tokens
          0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
            parse logicNonTerminal /wi eq {
              [
                { 0 parse * logicNonTerminal /wa eq } {
                  [
                    { 0 0 parse * * logicNonTerminal /wa eq } {
                      /anassrs goal use
                      goal [ |auto ] tacAttemptNext
                      goal .isopen { 0 =doRewrite } { 4 goal .resolution .hypotheses * =goal } ? *
                    }
                    { 0 0 parse * * logicNonTerminal /w3a eq } {
                      /3imp1 goal use
                      goal [ |auto ] tacAttemptNext
                      goal .isopen { 0 =doRewrite } { 5 goal .resolution .hypotheses * =goal } ? *
                    }
                    { 1 } {
                      /impcom goal use
                      goal [ |auto ] tacAttemptNext
                      goal .isopen { 0 =doRewrite } { 3 goal .resolution .hypotheses * =goal } ? *
                    }
                  ] conds
                  1
                }
                { 0 parse * logicNonTerminal /w3a eq } {
                  /3imp goal use
                  goal [ |auto ] tacAttemptNext
                  goal .isopen { 0 =doRewrite } { 4 goal .resolution .hypotheses * =goal } ? *
                  1
                }
                { 1 } { 0 }
              ] conds
            } { 0 } ? *
          } { 0 } ? *
          doRewrite and
        } { } loop

        goal tacNormalizeAntecedent
      } rep
    } /tacNormalizeAntecedent2 deffst

    { ==goal
      { "\e[31mnormalize:ante not applicable, expected |- ...\e[0m\n" out } =*notApplicable
      goal .thm expandMeta ==tokens
      0 tokens * "|-" eq { 1 tokens /wff logicParsers * * } andif tokens fullyParsed { ==parse
        parse logicNonTerminal /wi eq {
          1 parse * logicNonTerminal /wi eq {
            /expcom goal use
            goal [ |auto |tacNormalizeAntecedent |tacNormalizeAntecedent2 ] tacAttemptNext
          } {
            goal tacNormalizeAntecedent2
          } ? *
        } rep
      } |notApplicable ? *
    } /tacNormalizeAntecedent deffst

    { ==goals
      {
        [ goals { ==goal
          goal .isopen {
            goal .thm expandMeta ==tokens
            0 tokens * "|-" eq { 1 tokens /wff metaLogicParsers * * } andif tokens fullyParsed { ==parse
              parse logicNonTerminal /wi eq
                  { 0 parse * logicNonTerminal [ /wb /wceq ] eq any } andif
                  { 1 parse * logicNonTerminal [ /wb /wceq ] eq any } andif {
                0 1 parse * * logicRange tokens * ==leftMeta
                1 1 parse * * logicRange tokens * ==rightMeta
                [
                  { leftMeta tokensAreMetaVar rightMeta tokensAreMetaVar not and } {
                    1 0 parse * * logicRange tokens * ==from
                    0 0 parse * * logicRange tokens * ==to
                    1 1 parse * * logicRange tokens * from to rewriteTokens 0 leftMeta * let
                  }

                  { leftMeta tokensAreMetaVar not rightMeta tokensAreMetaVar and } {
                    0 0 parse * * logicRange tokens * ==from
                    1 0 parse * * logicRange tokens * ==to
                    0 1 parse * * logicRange tokens * from to rewriteTokens 0 rightMeta * let
                  }
                ] conds

                goal .thm expandMeta ==tokensSubstituted
                1 tokensSubstituted /wff logicParsers * * tokensSubstituted fullyParsed { --
                  goal tacDistrAntecedent
                  goal .isopen not { 1 } rep # repeat
                } rep
              } rep
            } rep
          } rep
        } each ] len
      } { } loop
    } /tacSubstitutions deffst

    # Models all known truths as an accepting FSM. Theorem variables become
    # self-loops, theorem tokens become transitions.
    { < map ==transitions objset ==theorems > } /tokenNode deffst

    { tokenNode _ ==theoremTokenIndex # returned
      [| "Indexing theorems by tokens...\n" |] out

      { ==name ==tokens
        objset ==i theoremTokenIndex i .put

        tokens { ==tok
          tok constants .has {
            objset ==newI
            i { ==n
              tok n .transitions .has not { tokenNode tok n .transitions =[] } rep
              tok n .transitions * newI .put
            } each
            newI =i
          } rep
        } each

        i { ==n
          name n .theorems .put
        } each
      } /index deffst

      assertions dom { ==name name assertions * .thm name index } each
      [ |collectEHyps |collectFHyps ] { =*collect
        proofContext collect ==hyps hyps dom { ==name
          name hyps * name index
        } each
      } each
    } memoized /theoremTokenIndex deffst

    { ==tokens
      objset ==i
      theoremTokenIndex i .put
      tokens { ==tok
        i { ==n
          tok n .transitions .has {
            tok n .transitions * i .put
          } rep
        } each
      } each

      [| "Possible theorems:\n" |] out
      i { .theorems 0 ==some { ==thm
        # thm tokens canUse { thm " " cat out 1 =some } rep
        thm " " cat out 1 =some
      } each some { "\n" out } rep } each
    } /search deffst

    { .thm expandMeta search } /suggest deffst

    { ==includeTypes
      0 ==i
      { ==indent ==goal
        includeTypes 0 goal .thm expandMeta * "|-" eq or {
          [|
            i txt .produce .u _ out ")" out len
            indent -01 sub { " " } rep
            goal .isopen { "\e[31m???\e[0m " } { goal .resolution .theorem .name " " } ? *
            goal .thm expandMeta { renderName " " } each "\n"
          |] out
        } rep
        i 1 add =i
        goal .isopen not { goal .resolution .hypotheses { indent 2 add recurse } each } rep
      } /recurse deffst
      mainGoal 4 recurse
    } /tree deffst

    {
      { ==goal
        goal .isopen not { goal .resolution .hypotheses |recurse each } rep
        [| goal .isopen { "? " } { goal .resolution .theorem .name " " } ? * |] out
      } /recurse deffst
      mainGoal recurse
      "$.\n" out
    } /export deffst

    { ==toReopen
      0 ==i
      { ==goal
        i _ 1 add =i toReopen eq { goal .open } rep
        goal .isopen not { goal .resolution .hypotheses |recurse each } rep
      } /recurse deffst
      mainGoal recurse
    } /reopen deffst

    { objset _ ==children .put
      { ==goal
        goal .isopen not {
          goal .resolution .hypotheses { ==hyp
            hyp children .has { goal .open } { hyp recurse } ? *
          } each
        } rep
      } /recurse deffst
      mainGoal recurse
    } /reopenParentOf deffst

    1 ==running
    0 ==autoall
    0 ==antedisp

    { running } {
      proofContext _ =userContext =renderContext
      mainGoal openGoals ==goals
      autoall { goals |auto each mainGoal openGoals =goals } rep

      { selectedGoal goals len ge selectedGoal 0 gt and } { selectedGoal 1 sub =selectedGoal } loop

      {
        " " ==sep
        [| nonDisj dom sort { ==x
          x nonDisj * dom sort { ==y
            sep ", " =sep x renderName " <=> " y renderName
          } each
        } each "\n" |] out
        [| disj dom sort { ==x
          x disj * dom sort { ==y
            sep ", " =sep x renderName " <!> " y renderName
          } each
        } each "\n" |] out

        goals dom { ==i
          i selectedGoal eq "\e[1m" "" ? ==hl
          [| hl i txt .produce .u ") " i goals * .thm expandMeta { hl -01 renderName " " } each "\e[0m\n" |] out
        } each

        antedisp { goals len } andif {
          selectedGoal goals * ==goal
          goal .thm expandMeta ==tokens
          0 tokens * "|-" eq { 1 tokens /wff metaLogicParsers * * } andif tokens fullyParsed { ==parse
            [| "\n" |] out
            proofContext collectEHyps _ ==hyps dom { ==name
              [| "+ " name hyps * _ len 1 -01 range -01* { renderName " " } each "\n" |] out
            } each
            goal antecedents ==antes
            [| "\n" |] out
            antes { ==toks
              [| "* " toks { renderName " " } each "\n" |] out
            } each
            [| "\e[1m-------------------------------------------------\e[0m\n" |] out
            [| "  "
               parse logicNonTerminal /wi eq { 1 parse * } { parse } ? * logicRange tokens *
                 { renderName " " } each
           "\n" |] out
          } rep
        } rep
      } /display deffst
      redisplay |display rep
      1 =redisplay

      "proof> " sys .out .writeall
      inputLine ==input

      { "\e[32mWe are done here.\e[0m\n" out } =*solved
      [
        { input "" eq } { 0 =running }
        { input "^ *quit\n" regex } { 0 =running }
        { input "^ *what\n" regex } { display 0 =redisplay }
        { input "^ *show (.*)\n" regex } { show 0 =redisplay }
        { input "^ *(\\d+)\n" regex } {
          txt .consume .u _ goals len ge { -- goals len 1 sub } rep =selectedGoal
        }
        { input "^ *use (.*)\n" regex } { selectedGoal goals * tacUse }
        { input "^ *let (\\$[^=]+) = (.*)\n" regex } { ==metaVar " " str .split { "" neq } grep ==tokens
          tokens metaVar let
        }
        { input "^ *unlet (\\$[^=]+)\n" regex } { ==v [ v ] v metaSubstitution =[] }
        { input "^ *lets\n" regex } {
          metaSubstitution dom { ==v
            [| v " = " v metaSubstitution * { renderName " " } each "\n" |] out
          } each
          0 =redisplay
        }
        { input "^ *nondisj (.*) <=> (.*)\n" regex } { markNonDisj }
        { input "^ *auto\n" regex
          input "^ *\n" regex or } { goals len { selectedGoal goals * auto } |solved ? * }
        { input "^ */(.*)\n" regex } { ==search 0 ==success
          goals dom { ==i
            1 neg [ [| i goals * .thm expandMeta { " " } each |] search regex ] * { success not } andif {
              i =selectedGoal 1 =success
            } rep
          } each
          success not { "\e[31mno such goal found\e[0m\n" out } rep
        }
        { input "^ *distr:ante\n" regex } { goals len { selectedGoal goals * tacDistrAntecedentMeta } |solved ? * }
        { input "^ *rewrite:ante\n" regex } { goals len { selectedGoal goals * tacRewriteAntecedent } |solved ? * }
        { input "^ *and rewrite\n" regex } { goals len { selectedGoal goals * tacContinueWithRewrite } |solved ? * }
        { input "^ *rewrite:full (.*)\n" regex } { " " str .split { "" neq } grep ==tokens
          goals len { tokens selectedGoal goals * tacRewriteFull } |solved ? * }
        { input "^ *substitutions\n" regex } { goals tacSubstitutions }
        { input "^ *under (.*)\n" regex } { " " str .split { "" neq } grep ==tokens
          goals len { tokens selectedGoal goals * tacUnder } |solved ? * }
        { input "^ *with only (.*)\n" regex } { " " str .split { "" neq } grep ==tokens
          goals len { tokens selectedGoal goals * tacWithOnly } |solved ? * }
        { input "^ *with (.*)\n" regex } { " " str .split { "" neq } grep ==tokens
          goals len { tokens selectedGoal goals * tacWith } |solved ? * }
        { input "^ *conclude (.*)\n" regex } { " " str .split { "" neq } grep ==tokens
          goals len { tokens selectedGoal goals * tacConclude } |solved ? * }
        { input "^ *and conclude (.*)\n" regex } { " " str .split { "" neq } grep ==tokens
          goals len { tokens selectedGoal goals * tacAndConclude } |solved ? * }
        { input "^ *normalize:ante\n" regex } {
          goals len { selectedGoal goals * tacNormalizeAntecedent } |solved ? * }
        { input "^ *expand (.*)\n" regex } { ==name
          goals len { name selectedGoal goals * tacExpand } |solved ? * }
        { input "^ *tree\n" regex } { 0 tree }
        { input "^ *fulltree\n" regex } { 1 tree }
        { input "^ *export\n" regex } { export }
        { input "^ *reopen (\\d+)\n" regex } { txt .consume .u reopen }
        { input "^ *reopen\n" regex } { selectedGoal goals * reopenParentOf }
        { input "^ *sug\n" regex } { selectedGoal goals * suggest }
        { input "^ *search (.*)\n" regex } { " " str .split _ =lastSearch search }
        { input "^ *search\n" regex } { lastSearch search }
        { input "^ *parse\n" regex } {
          0 selectedGoal goals * .thm * ==head

          [
            { head "|-" eq }           { [ 1 selectedGoal goals * .thm expandMeta /wff logicParsers * * ] dump }
            { head logicParsers .has } { [ 1 selectedGoal goals * .thm expandMeta head logicParsers * * ] dump }
            { 1 } { [| "\e[31mno parser available\e[0m\n" |] out }
          ] conds
        }
        { input "^ *autoall\n" regex } { 1 =autoall }
        { input "^ *noautoall\n" regex } { 0 =autoall }
        { input "^ *antedisp\n" regex } { 1 =antedisp }
        { input "^ *noantedisp\n" regex } { 0 =antedisp }
      ] conds
    } loop
  } /proveProposition deffd

  { ==name
    name assertions .has { name assertions * .type "p" eq } { 0 } ? * {
      name assertions * proveProposition
    } {
      [| name " is not a provable proposition\n" |] out
      name show
    } ? *
  } /prove deffd

  { map _ ==variables # returned
    blocks { .f _ =*d dom 
      { _ ==n d _ 0 -01 * ==nonterminal 1 -01 * ==var
        nonterminal var variables =[]
      } each
    } each
  } memoized /variables deffd

  # generate parser functions
  # { ==toks ==start [...] used_theorem end success[0/1] }
  { =*variableCases
    map ==nonterminals
    map ==variableNonTerminals # nonterminal -> variable -> theorem name

    blocks { .f _ =*d dom 
      { _ ==thm d _ 0 -01 * ==nonterminal 1 -01 * ==var
        nonterminal variableNonTerminals .has not { map nonterminal variableNonTerminals =[] } rep
        nonterminal variableNonTerminals * ==variableTypedefs # variable -> theorem name

        var variableTypedefs .has { var variableTypedefs * len thm len gt } { 1 } ? *
          { thm var variableTypedefs =[] } rep
      } each
    } each

    variableNonTerminals nonterminals variableCases

    assertions dom { _ ==name assertions * ==a
      a .type "a" eq {
        0 a .thm * _ ==nt nonterminals .has {
          a .ctx collectEHyps dom len 0 eq {
            1 a .thm len range a .thm * ==expectedTokens
            nt nonterminals * =*alt

            { ==toks _ ==start ==i
              start toks alt { 1 } {
                1 ==success , [
                expectedTokens { ==tok success {
                  tok constants .has {
                    i toks len lt { i toks * tok eq } andif { i 1 add =i } { 0 =success } ? *
                  } {
                    i toks tok variables * nonterminals * * { =i } { 0 =success } ? *
                  } ? *
                } rep } each
                success { ,-- start i name ] i 1 } { ,--- 0 } ? *
              } ? *
            } nt nonterminals =[]
          } rep
        } rep
      } rep
    } each

    map ==cache # for packrat transformation
    nonterminals dom { ==nt
      nt nonterminals * =*orig
      { ==toks ==start
        nt cache .has not { map nt cache =[] } rep nt cache * ==ntCache
        start txt .produce .hu ==cacheKey
        cacheKey ntCache .has not { [ start toks orig ] cacheKey ntCache =[] } rep
        cacheKey ntCache * _ len dearray
      } nt nonterminals =[]
    } each

    map ==globalCache # for repeated invocations
    map _ ==parsers # returned
    nonterminals dom { ==nt {
      ==toks ==start
      [| nt toks { " " } each start txt .produce .hu |] ==cacheKey
      cacheKey globalCache .has not {
        [ map =cache start toks nt nonterminals * * ] cacheKey globalCache =[] # reset local cache before parse
      } rep
      cacheKey globalCache * _ len dearray
    } nt parsers =[] } each
  } /generateLogicParsers deffd

  { ==nonterminals ==variableNonTerminals
    variableNonTerminals dom { ==nonterminal
      nonterminal variableNonTerminals * ==validVars
      { ==toks ==start
        start toks len lt { start toks * validVars .has } andif { [ start _ 1 add start toks * validVars * ] start 1 add 1 } { 0 } ? *
      } nonterminal nonterminals =[]
    } each
  } /noMetaVariables deffst

  { ==nonterminals ==variableNonTerminals
    variableNonTerminals dom { ==nonterminal
      nonterminal variableNonTerminals * ==validVars
      { ==toks ==start
        start toks len lt {
          start toks * ==var
          var len { 0 var * 0 "$" * eq } andif { var ".(.*)\\.[0-9]+" regex } andif { =var } rep
          var validVars .has { [ start _ 1 add var validVars * ] start 1 add 1 } { 0 } ? *
        } rep
      } nonterminal nonterminals =[]
    } each
  } /alsoMetaVariables deffst

  { [| "Generating logic parser...\n"      |] out |noMetaVariables   generateLogicParsers } memoized /logicParsers deffst
  { [| "Generating meta-logic parser...\n" |] out |alsoMetaVariables generateLogicParsers } memoized /metaLogicParsers deffst

  { ==node node len 3 sub node * } /logicStart deffst
  { ==node node len 2 sub node * } /logicEnd deffst
  { ==node node len _ 3 sub node * -01 2 sub node * range } /logicRange deffst
  { ==node node len 1 sub node * } /logicNonTerminal deffst
  { ==tokens { tokens len eq { 1 } { -- 0 } ? * } { 0 } ? * } /fullyParsed deffst

  { ==name
    [
      { name assertions .has } {
        name assertions * ==a
        [ 1 a .thm /wff logicParsers * * ] dump
      }
      { 1 } { [| "\e[31m" name " is not a proposition\e[0m" |] dump }
    ] conds
  } /parseTokens deffd

  {
    1 ==running
    { running } {
      "> " sys .out .writeall
      inputLine ==input

      [
        { input "" eq } { 0 =running }
        { input "^ *quit\n" regex } { 0 =running }
        { input "^ *show (.*)\n" regex } { show }
        { input "^ *parse (.*)\n" regex } { parseTokens }
        { input "^ *prove (.*)\n" regex } { prove }
      ] conds
    } loop
  }
> -- /interactive deffd

interactive
#
# {
#   sys .argv len { 0 sys .argv * } { "/proc/self/fd/0" } ? * include
#   0 sys .exit
# }' "igor.loaded" sys .freeze

# vim: syn=elymas
